{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygQ9-7WAhmSy"
      },
      "source": [
        "# T-725 Natural Language Processing: Lab 9\n",
        "In today's lab, we will be working with **semantic analysis**.\n",
        "\n",
        "To begin with, do the following:\n",
        "* Select `\"File\" > \"Save a copy in Drive\"` to create a local copy of this notebook that you can edit.\n",
        "* Select `\"Runtime\" > \"Run all\"` to run the code in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqxqo7qUcelk",
        "outputId": "88169863-b500-48e7-b6bf-917d76ef64a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('book_grammars')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package book_grammars to /root/nltk_data...\n",
            "[nltk_data]   Package book_grammars is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJfa4OI_cfQ1"
      },
      "source": [
        "## Feature-based grammars\n",
        "\n",
        "Consider the following context free grammar:\n",
        "\n",
        "```\n",
        "S   ->   NP VP\n",
        "NP  ->   Det N\n",
        "VP  ->   V\n",
        "\n",
        "Det  ->  'this' | 'these'\n",
        "N    ->  'dog' | 'dogs'\n",
        "V    ->  'run' | 'runs'\n",
        "```\n",
        "\n",
        "While it can parse and generate the sentences \"*this dog runs*\" and \"*these dogs run*\", it can also generate ungrammatical sentences such as \"*this dogs runs*\" and \"*these dog run*\". We can edit the grammar to ensure that verbs and their subjects, as well as nouns and determiners, agree in number:\n",
        "\n",
        "```\n",
        "S -> NP_SG VP_SG | NP_PL VP_PL\n",
        "NP_SG -> Det_SG N_SG\n",
        "NP_PL -> Det_PL N_PL\n",
        "VP_SG -> V_SG\n",
        "VP_PL -> V_PL\n",
        "\n",
        "Det_SG -> 'this'\n",
        "Det_PL -> 'these'\n",
        "N_SG -> 'dog'\n",
        "N_PL -> 'dogs'\n",
        "V_SG -> 'runs'\n",
        "V_PL -> 'run'\n",
        "```\n",
        "\n",
        "Unfortunately, this comes at the cost of doubling the number of productions. The grammar will quickly grow in size as we continue to add to it. Let's look at a more concise way to define the revised grammar:\n",
        "\n",
        "```\n",
        "S -> NP[NUM=?n] VP[NUM=?n]\n",
        "NP[NUM=?n] -> Det[NUM=?n] N[NUM=?n]\n",
        "VP[NUM=?n] -> V[NUM=?n]\n",
        "\n",
        "Det[NUM=sg] -> 'this'\n",
        "Det[NUM=pl] -> 'these'\n",
        "N[NUM=sg] -> 'dog'\n",
        "N[NUM=pl] -> 'dogs'\n",
        "V[NUM=sg] -> 'runs'\n",
        "V[NUM=pl] -> 'run'\n",
        "```\n",
        "\n",
        "This is known as a *feature-based grammar* (see [Chapter 9](http://www.nltk.org/book/ch09.html) of the NLTK book). Instead of creating specific categories for the number, we create a *feature* called `NUM` which we can assign to different categories. We also allow *variables* over feature values, which are used to state constraints. In the grammar above, `NUM=?n` specifies that the number can be either singular, `sg`, or plural, `pl`. The production `S -> NP[NUM=?n] VP[NUM=?n]` means that `NUM` must take the same value for `NP` and `VP`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lfYlzndclG1"
      },
      "source": [
        "## First-order logic\n",
        "If we know that all dogs bark, and that Cyril is a dog, then we also know that Cyril barks. This line of reasoning can be formally stated using [first-order logic](http://www.nltk.org/book/ch10.html#sec-fol):\n",
        "\n",
        "* $\\forall{x}(dog(x) \\implies barks(x))$: All dogs bark.\n",
        "  * The $\\forall$ symbol means \"for all\" and $A\\implies B$ means \"if $A$ is true, then $B$ is also true\", or \"$A$ implies $B$\".\n",
        "* $dog(Cyril)$: Cyril is a dog\n",
        "* $dog(Cyril) \\implies barks(Cyril)$: If Cyril is a dog, then Cyril barks.\n",
        "* $barks(Cyril)$: Cyril barks.\n",
        "\n",
        "In the NLTK, these statements are expressed in the following way:\n",
        "* `all x.(dog(x) -> barks(x))`\n",
        "* `dog(Cyril)`\n",
        "* `dog(Cyril) -> barks(Cyril)`\n",
        "* `barks(Cyril)`\n",
        "\n",
        "You can perform syntax-driven semantic analysis of natural language input sentences by building an NLTK parser from a feature-based grammar that contains semantic attachments as features. Such a parser constructs statements like the ones above as it parses sentences.\n",
        "\n",
        "Building the parser is as simple as calling `nltk.load_parser(\"<fcfg filename>\")` and assigning the resulting parser object to a variable like `parser`. NLTK creates the right kind of parser by inspecting the grammar. Let's take a look at one such grammar, `simple-sem.fcfg`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnM2P7nkDji6",
        "outputId": "32391a56-2f51-4388-f52b-a62df714a74e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cat /root/nltk_data/grammars/book_grammars/simple-sem.fcfg"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Natural Language Toolkit: sem3.fcfg\n",
            "##\n",
            "## Alternative simple grammar with transitive verbs and \n",
            "## quantifiers for the book. \n",
            "## \n",
            "## Author: Ewan Klein <ewan@inf.ed.ac.uk> \n",
            "## URL: <http://nltk.sourceforge.net>\n",
            "## For license information, see LICENSE.TXT\n",
            "\n",
            "\n",
            "% start S\n",
            "############################\n",
            "# Grammar Rules\n",
            "#############################\n",
            "\n",
            "S[SEM = <?subj(?vp)>] -> NP[NUM=?n,SEM=?subj] VP[NUM=?n,SEM=?vp]\n",
            "\n",
            "NP[NUM=?n,SEM=<?det(?nom)> ] -> Det[NUM=?n,SEM=?det]  Nom[NUM=?n,SEM=?nom]\n",
            "NP[LOC=?l,NUM=?n,SEM=?np] -> PropN[LOC=?l,NUM=?n,SEM=?np]\n",
            "\n",
            "Nom[NUM=?n,SEM=?nom] -> N[NUM=?n,SEM=?nom]\n",
            "\n",
            "VP[NUM=?n,SEM=?v] -> IV[NUM=?n,SEM=?v]\n",
            "VP[NUM=?n,SEM=<?v(?obj)>] -> TV[NUM=?n,SEM=?v] NP[SEM=?obj]\n",
            "VP[NUM=?n,SEM=<?v(?obj,?pp)>] -> DTV[NUM=?n,SEM=?v] NP[SEM=?obj] PP[+TO,SEM=?pp]\n",
            "\n",
            "PP[+TO, SEM=?np] -> P[+TO] NP[SEM=?np]\n",
            "\n",
            "#############################\n",
            "# Lexical Rules\n",
            "#############################\n",
            "\n",
            "PropN[-LOC,NUM=sg,SEM=<\\P.P(angus)>] -> 'Angus'\n",
            "PropN[-LOC,NUM=sg,SEM=<\\P.P(cyril)>] -> 'Cyril'\n",
            "PropN[-LOC,NUM=sg,SEM=<\\P.P(irene)>] -> 'Irene'\n",
            "\n",
            "Det[NUM=sg,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'every'\n",
            "Det[NUM=pl,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'all'\n",
            "Det[SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'some'\n",
            "Det[NUM=sg,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'a'\n",
            "Det[NUM=sg,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'an'\n",
            "\n",
            "N[NUM=sg,SEM=<\\x.man(x)>] -> 'man'\n",
            "N[NUM=sg,SEM=<\\x.girl(x)>] -> 'girl'\n",
            "N[NUM=sg,SEM=<\\x.boy(x)>] -> 'boy'\n",
            "N[NUM=sg,SEM=<\\x.bone(x)>] -> 'bone'\n",
            "N[NUM=sg,SEM=<\\x.ankle(x)>] -> 'ankle'\n",
            "N[NUM=sg,SEM=<\\x.dog(x)>] -> 'dog'\n",
            "N[NUM=pl,SEM=<\\x.dog(x)>] -> 'dogs'\n",
            "\n",
            "IV[NUM=sg,SEM=<\\x.bark(x)>,TNS=pres] -> 'barks'\n",
            "IV[NUM=pl,SEM=<\\x.bark(x)>,TNS=pres] -> 'bark'\n",
            "IV[NUM=sg,SEM=<\\x.walk(x)>,TNS=pres] -> 'walks'\n",
            "IV[NUM=pl,SEM=<\\x.walk(x)>,TNS=pres] -> 'walk'\n",
            "TV[NUM=sg,SEM=<\\X x.X(\\y.chase(x,y))>,TNS=pres] -> 'chases'\n",
            "TV[NUM=pl,SEM=<\\X x.X(\\y.chase(x,y))>,TNS=pres] -> 'chase'\n",
            "TV[NUM=sg,SEM=<\\X x.X(\\y.see(x,y))>,TNS=pres] -> 'sees'\n",
            "TV[NUM=pl,SEM=<\\X x.X(\\y.see(x,y))>,TNS=pres] -> 'see'\n",
            "TV[NUM=sg,SEM=<\\X x.X(\\y.bite(x,y))>,TNS=pres] -> 'bites'\n",
            "TV[NUM=pl,SEM=<\\X x.X(\\y.bite(x,y))>,TNS=pres] -> 'bite'\n",
            "DTV[NUM=sg,SEM=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>,TNS=pres] -> 'gives'\n",
            "DTV[NUM=pl,SEM=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>,TNS=pres] -> 'give'\n",
            "\n",
            "P[+to] -> 'to'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yS_J8hiYefz"
      },
      "source": [
        "Let's parse a few sentences using this grammar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoctYgR5cnKy",
        "outputId": "15afcaae-6bdd-4bd3-e160-d19b6a2e3f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "parser = nltk.load_parser('grammars/book_grammars/simple-sem.fcfg', trace=0)\n",
        "\n",
        "sentences = ['all dogs bark', 'Angus gives a bone to every dog']\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(sentence)\n",
        "  tokens = sentence.split()\n",
        "\n",
        "  for tree in parser.parse(tokens):\n",
        "    #print(tree)\n",
        "    print(tree.label()['SEM'])\n",
        "  print()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all dogs bark\n",
            "all x.(dog(x) -> bark(x))\n",
            "\n",
            "Angus gives a bone to every dog\n",
            "all z15.(dog(z15) -> exists z14.(bone(z14) & give(angus,z14,z15)))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV2fEwwHhmqY"
      },
      "source": [
        "# Assignment\n",
        "Answer the following questions and hand in your solution in Canvas before 8:30 Monday morning, October 30th. Remember to save your file before uploading it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK_dFKnahnJ1"
      },
      "source": [
        "## Question 1\n",
        "Add to the lexicon in `my_grammar` below so that additional sentences of your choosing can be parsed (e.g., *some people play an instrument*). You do not need to modify or add any grammar rules, you only need to add new **lexical rules** at the end of the string that is assigned to `my_grammar`. Confirm that you get the FOL representation you expect.\n",
        "\n",
        "**Note**: If you have the proper lexical rules and still cannot parse your sentence, you may need to rephrase it. For example, this simple grammar cannot parse the sentence \"*some people play instruments*\", but it can parse \"*some people play an instrument*\" or \"*some people play some instruments*\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAHCnR2ChoBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2399a701-b7f5-46fd-f854-7067d92d74e3"
      },
      "source": [
        "my_grammar = r\"\"\"\n",
        "% start S\n",
        "############################\n",
        "# Grammar Rules\n",
        "#############################\n",
        "\n",
        "S[SEM = <?subj(?vp)>] -> NP[NUM=?n,SEM=?subj] VP[NUM=?n,SEM=?vp]\n",
        "\n",
        "NP[NUM=?n,SEM=<?det(?nom)> ] -> Det[NUM=?n,SEM=?det]  Nom[NUM=?n,SEM=?nom]\n",
        "NP[LOC=?l,NUM=?n,SEM=?np] -> PropN[LOC=?l,NUM=?n,SEM=?np]\n",
        "\n",
        "Nom[NUM=?n,SEM=?nom] -> N[NUM=?n,SEM=?nom]\n",
        "\n",
        "VP[NUM=?n,SEM=?v] -> IV[NUM=?n,SEM=?v]\n",
        "VP[NUM=?n,SEM=<?v(?obj)>] -> TV[NUM=?n,SEM=?v] NP[SEM=?obj]\n",
        "VP[NUM=?n,SEM=<?v(?obj,?pp)>] -> DTV[NUM=?n,SEM=?v] NP[SEM=?obj] PP[+TO,SEM=?pp]\n",
        "\n",
        "PP[+TO, SEM=?np] -> P[+TO] NP[SEM=?np]\n",
        "\n",
        "#############################\n",
        "# Lexical Rules\n",
        "#############################\n",
        "\n",
        "PropN[-LOC,NUM=sg,SEM=<\\P.P(angus)>] -> 'Angus'\n",
        "PropN[-LOC,NUM=sg,SEM=<\\P.P(cyril)>] -> 'Cyril'\n",
        "PropN[-LOC,NUM=sg,SEM=<\\P.P(irene)>] -> 'Irene'\n",
        "\n",
        "Det[NUM=sg,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'every'\n",
        "Det[NUM=pl,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'all'\n",
        "Det[SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'some'\n",
        "Det[NUM=sg,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'a'\n",
        "Det[NUM=sg,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'an'\n",
        "\n",
        "N[NUM=sg,SEM=<\\x.man(x)>] -> 'man'\n",
        "N[NUM=sg,SEM=<\\x.girl(x)>] -> 'girl'\n",
        "N[NUM=sg,SEM=<\\x.boy(x)>] -> 'boy'\n",
        "N[NUM=sg,SEM=<\\x.bone(x)>] -> 'bone'\n",
        "N[NUM=sg,SEM=<\\x.ankle(x)>] -> 'ankle'\n",
        "N[NUM=sg,SEM=<\\x.dog(x)>] -> 'dog'\n",
        "N[NUM=pl,SEM=<\\x.dog(x)>] -> 'dogs'\n",
        "\n",
        "IV[NUM=sg,SEM=<\\x.bark(x)>,TNS=pres] -> 'barks'\n",
        "IV[NUM=pl,SEM=<\\x.bark(x)>,TNS=pres] -> 'bark'\n",
        "IV[NUM=sg,SEM=<\\x.walk(x)>,TNS=pres] -> 'walks'\n",
        "IV[NUM=pl,SEM=<\\x.walk(x)>,TNS=pres] -> 'walk'\n",
        "TV[NUM=sg,SEM=<\\X x.X(\\y.chase(x,y))>,TNS=pres] -> 'chases'\n",
        "TV[NUM=pl,SEM=<\\X x.X(\\y.chase(x,y))>,TNS=pres] -> 'chase'\n",
        "TV[NUM=sg,SEM=<\\X x.X(\\y.see(x,y))>,TNS=pres] -> 'sees'\n",
        "TV[NUM=pl,SEM=<\\X x.X(\\y.see(x,y))>,TNS=pres] -> 'see'\n",
        "TV[NUM=sg,SEM=<\\X x.X(\\y.bite(x,y))>,TNS=pres] -> 'bites'\n",
        "TV[NUM=pl,SEM=<\\X x.X(\\y.bite(x,y))>,TNS=pres] -> 'bite'\n",
        "DTV[NUM=sg,SEM=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>,TNS=pres] -> 'gives'\n",
        "DTV[NUM=pl,SEM=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>,TNS=pres] -> 'give'\n",
        "\n",
        "P[+to] -> 'to'\n",
        "\n",
        "# New Lexical Rules\n",
        "#############################\n",
        "N[NUM=pl,SEM=<\\x.person(x)>] -> 'people'\n",
        "TV[NUM=pl,SEM=<\\X x.X(\\y.play(x,y))>,TNS=pres] -> 'play'\n",
        "N[NUM=sg,SEM=<\\x.instrument(x)>] -> 'instrument'\n",
        "N[NUM=sg,SEM=<\\x.instrument(x)>] -> 'instruments'\n",
        "\"\"\"\n",
        "\n",
        "grammar = nltk.grammar.FeatureGrammar.fromstring(my_grammar)\n",
        "parser = nltk.parse.FeatureEarleyChartParser(grammar)\n",
        "\n",
        "# Parse your sentences here, after modifying the grammar above.\n",
        "# Hint: Copy the code from the last parsing example above, you can use the same code to assign sentences and printing out the parse results.\n",
        "sentences = ['some people play an instrument', 'some people play some instruments']\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(sentence)\n",
        "  tokens = sentence.split()\n",
        "\n",
        "  for tree in parser.parse(tokens):\n",
        "    #print(tree)\n",
        "    print(tree.label()['SEM'])\n",
        "  print()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "some people play an instrument\n",
            "exists x.(person(x) & exists z16.(instrument(z16) & play(x,z16)))\n",
            "\n",
            "some people play some instruments\n",
            "exists x.(person(x) & exists z17.(instrument(z17) & play(x,z17)))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om1IP2gfhnu8"
      },
      "source": [
        "## Question 2\n",
        "Our parser generates FOL representations for sentences in English, but it is not capable of evaluating them. You can build a model in the NLTK using the exact same set-based model-theoretic semantics as the text book explains in Chapter 15.2 and shows in Figure 15.2. Note that an NLTK model already specifies a certain denotation and interpretation. That is, you include specific Objects, Properties and Relations and associate them with certain elements of the domain, sets and sets of tuples, respectively.\n",
        "\n",
        "**Building a model**\n",
        "\n",
        "You build the model object from a special string representation of the model using the `nltk.Valuation.fromstring()` function, which returns a so-called valuation. If you store the valuation in a variable, you can pass it, along with its domain, into the constructor of a new Model: `m = nltk.Model(val.domain, val)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erir6KyPxidS"
      },
      "source": [
        "model_representation = \"\"\"\n",
        "spot => s\n",
        "dog => {s}\n",
        "bark => {s}\n",
        "\"\"\"\n",
        "\n",
        "# Build the model\n",
        "val = nltk.Valuation.fromstring(model_representation)\n",
        "var_assignments = nltk.Assignment(val.domain)\n",
        "m = nltk.Model(val.domain, val)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t44EQAiVxk2P"
      },
      "source": [
        "**Evaluating FOL statements**\n",
        "\n",
        "You can then start evaluating FOL statements (in string format) against the model like this: `m.evaluate(\"all x.(dog(x) -> bark(x))\", nltk.Assignment(val.domain))` (The second parameter contains any variable substitutions if there are any, in this case there are none and we are passing the default assignments)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY-R56Y2xlSM",
        "outputId": "dd59ded3-045f-469c-d93c-bae3de344739",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate a semantic representation\n",
        "m.evaluate(\"all x.(dog(x) -> bark(x))\", var_assignments)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPMK9QiWxqv4"
      },
      "source": [
        "More examples can be found in [Chapter 10](http://www.nltk.org/book/ch10.html#truth-in-model) of the NLTK book.\n",
        "\n",
        "Add to the model representation below so that it can be used to evaluate the sentences you had in mind in Question 1. Test your model by evaluating various statements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy0aURJCcoyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ff20e0-3f40-4f12-d7f0-4bd6205d8b3d"
      },
      "source": [
        "model_representation = \"\"\"\n",
        "angus => a\n",
        "cyril => c\n",
        "irene => i\n",
        "boy => {a}\n",
        "girl => {i}\n",
        "dog => {c}\n",
        "walk => {i, c}\n",
        "see => {(a, i), (c, a), (i, c)}\n",
        "person => {a, i}\n",
        "instrument => {c}\n",
        "play => {(a, c), (i, c)}\n",
        "\"\"\"\n",
        "\n",
        "# Build your model and evaluate your statements here, after modifying the model above.\n",
        "\n",
        "val = nltk.Valuation.fromstring(model_representation)\n",
        "var_assignments = nltk.Assignment(val.domain)\n",
        "m = nltk.Model(val.domain, val)\n",
        "m.evaluate(\"exists x.(person(x) & exists z12.(instrument(z12) & play(x,z12)))\", var_assignments)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKFoZDGihoV9"
      },
      "source": [
        "## Question 3\n",
        "With the parser from Question 1 and model from Question 2, we can directly evaluate the truth value of English sentences, by:\n",
        "\n",
        "1. Translating an English sentence into a FOL statement like we did in Question 1.\n",
        "2. Using the resulting expression as the first argument to the `evaluate()` method of the model. However, we first need to convert the expression into a string (`semantic_expression = str(semantic_expression)`).\n",
        "3. Evaluating the truth value of the statement with the `evaluate()` method of the model, like we did in Question 2.\n",
        "\n",
        "Evaluate the truth value of several English sentences that are supported by the grammar from Question 1 and model from Question 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJFJ6wsMYw-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3c767f-3e34-435f-d8de-93bf9b699bd2"
      },
      "source": [
        "# parser from question 1\n",
        "def parse_sentence(sentence):\n",
        "  tokens = sentence.split()\n",
        "\n",
        "  for tree in parser.parse(tokens):\n",
        "    #print(tree)\n",
        "    return str(tree.label()['SEM'])\n",
        "# model from question 2\n",
        "def get_model(sentence):\n",
        "  val = nltk.Valuation.fromstring(model_representation)\n",
        "  var_assignments = nltk.Assignment(val.domain)\n",
        "  m = nltk.Model(val.domain, val)\n",
        "  return m, var_assignments\n",
        "\n",
        "def evaluate(sentence):\n",
        "  parsed = parse_sentence(sentence)\n",
        "  (model, var_assignments) = get_model(parsed)\n",
        "  return model.evaluate(parsed, var_assignments)\n",
        "\n",
        "sentences = [\n",
        "    'all people walk',\n",
        "    'Angus walks',\n",
        "    'some dogs walk',\n",
        "    'some people walk',\n",
        "]\n",
        "\n",
        "for sentence in sentences:\n",
        "    print(f'{sentence} - {evaluate(sentence)}')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all people walk - False\n",
            "Angus walks - False\n",
            "some dogs walk - True\n",
            "some people walk - True\n"
          ]
        }
      ]
    }
  ]
}