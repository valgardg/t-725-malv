{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}},"colab":{"provenance":[{"file_id":"1d3LkORC8fCjN8V5zCP015-0f55QT3tyC","timestamp":1725029189229}],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"id":"cA4f3BP_gZUC"},"source":["# T-725 Natural Language Processing: Lab 1\n","In these labs, we will be using the [Python 3](https://www.python.org/) programming language and the [Natural Language Toolkit (NLTK)](https://www.nltk.org/). We will also be using Google Colab, a free service hosted by Google, which gives us access to a Linux machine that comes pre-installed with Python 3 and the NLTK."]},{"cell_type":"markdown","metadata":{"id":"lMY8d4CJ46K2"},"source":["## Using Google Colab\n","Google Colab allows users to work with \"notebooks\", which consists of text cells and code cells. Text cells can be edited by double clicking them. A code cell can be executed by selecting it and pressing `Ctrl + Enter`. Code is shared between cells, meaning that you can, for example, create a variable in one cell and use it in another cell later on.\n","\n","To begin with, do the following:\n","* Select `\"File\" > \"Save a copy in Drive\"` to create a local copy of this notebook that you can edit.\n","* Select `\"Runtime\" > \"Run all\"` to run all of the code cells in the notebook.\n","\n","## Resources\n","* [The Python Standard Library](https://docs.python.org/3/library/index.html) - an overview of the built-in libraries in Python with a lot of examples.\n","* [The Python Tutorial](https://docs.python.org/3/tutorial/index.html) - an official tutorial that gives a brief overview of the language.\n","* [Automate the Boring Stuff with Python](https://automatetheboringstuff.com/) - a free book that offers a good introduction to the Python programming language to beginners.\n","* [Natural Language Processing with Python](http://www.nltk.org/book/) - a free companion book to the NLTK toolkit.\n","\n","## Setting Python and the NLTK up on your own machine\n","* [Python 3](https://realpython.com/installing-python/) - installation instructions\n","* [NLTK](https://www.nltk.org/install.html) - installation instructions"]},{"cell_type":"markdown","metadata":{"id":"f19uyslsaYw4"},"source":["## String methods in Python\n","There are many ways to manipulate strings in Python. A full list of methods for the String class may be found in the [library reference](https://docs.python.org/3/library/stdtypes.html#string-methods)."]},{"cell_type":"code","metadata":{"id":"nzTEm3RCgZUU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725030461076,"user_tz":240,"elapsed":191,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"67f583af-f9de-4e11-dfcd-e49c4f8594a5"},"source":["a_string = \"It was the best of times, it was the worst of times\"\n","\n","print(\"Lowercase:\", a_string.lower())\n","print(\"'times' count:\", a_string.count('times'))\n","print(\"First occurence of 'best':\", a_string.find('best'))"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Lowercase: it was the best of times, it was the worst of times\n","'times' count: 2\n","First occurence of 'best': 11\n"]}]},{"cell_type":"markdown","metadata":{"id":"lmTHYN-agZVa"},"source":["## Lists, sets and built-in functions\n","Lists and sets are two kinds of collections that can be used in Python.\n","* A **list** is an *ordered* sequence of elements. Lists are enclosed with square brackets, and the elements are separated with a comma (e.g., `a_list = [\"This\", \"is\", \"a\", \"list\"]`).\n","* A **set** is a collection of *unordered* and *unique* elements (meaning that it contains no duplicates). Sets are enclosed by curly braces, and the elements are separated by commas (e.g., `a_set = {\"This\", \"is\", \"a\", \"set\"}`)."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"8NWJM2rGgZVf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725030461266,"user_tz":240,"elapsed":18,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"5af9f573-0824-4274-8eda-761aea9f76d1"},"source":["# Variables can be converted to lists and sets with the list() and set() functions\n","char_list = list(a_string)\n","char_set = set(a_string)\n","\n","# You can also split strings on certain characters to create a list of strings\n","words = a_string.split()  # Splits on whitespaces by default\n","print(\"Split string:\", words)\n","\n","# The len() and max() built-in methods\n","print(\"Unique characters:\", char_set)\n","print(\"No. of unique characters:\", len(char_set))\n","print(\"Longest word:\", max(words, key=len))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Split string: ['It', 'was', 'the', 'best', 'of', 'times,', 'it', 'was', 'the', 'worst', 'of', 'times']\n","Unique characters: {',', 'I', ' ', 'm', 'i', 'w', 't', 'h', 'e', 'b', 'f', 'r', 'o', 's', 'a'}\n","No. of unique characters: 15\n","Longest word: times,\n"]}]},{"cell_type":"markdown","metadata":{"id":"lUt68ulEpfuw"},"source":["You can use the built-in function `help()` to quickly access documentation for a given object."]},{"cell_type":"code","metadata":{"id":"En1YvSC4qHJ8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725030461266,"user_tz":240,"elapsed":16,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"af7d092a-b914-4c20-9737-0525313fb1f9"},"source":["help(max)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on built-in function max in module builtins:\n","\n","max(...)\n","    max(iterable, *[, default=obj, key=func]) -> value\n","    max(arg1, arg2, *args, *[, key=func]) -> value\n","    \n","    With a single iterable argument, return its biggest item. The\n","    default keyword-only argument specifies an object to return if\n","    the provided iterable is empty.\n","    With two or more arguments, return the largest argument.\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"9X_TWoEUgZVw"},"source":["## Indices and slicing\n","You can get characters and substrings at specific indexes:"]},{"cell_type":"code","metadata":{"id":"_p4o5Lc_gZV2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725030461266,"user_tz":240,"elapsed":11,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"6651582b-62a0-4f18-f88e-faf49ecc24b2"},"source":["print(\"String:\", a_string)\n","print(\"First character:\", a_string[0])  # Indices in Python start at 0\n","print(\"Last character:\", a_string[-1])  # A negative index starts counting from the end\n","\n","# We can get ranges of elements by slicing a list\n","print(\"Characters 11 to 14:\", a_string[11:15])\n","print(\"First 6 characters:\", a_string[:6])\n","print(\"Last 5 characters:\", a_string[-5:])"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["String: It was the best of times, it was the worst of times\n","First character: I\n","Last character: s\n","Characters 11 to 14: best\n","First 6 characters: It was\n","Last 5 characters: times\n"]}]},{"cell_type":"markdown","metadata":{"id":"8wQ9qvZ2gZV_"},"source":["## The Natural Language Toolkit (NLTK)\n","The NLTK book, [Natural Language Processing with Python](http://www.nltk.org/book/), is an introduction to natural language processing in Python, using the NLTK library. [Chapter 1](http://www.nltk.org/book/ch01.html) is relevant to this lab. The NLTK comes with a lot of data, such as corpora and trained models. We can download this data with the `nltk.download()` function."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"txGWuokGgZWF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725030463786,"user_tz":240,"elapsed":2526,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"20ce493c-9a96-44a4-d02f-b05ffde73ac9"},"source":["import nltk\n","from nltk.corpus import gutenberg\n","\n","# Download the 'gutenberg' corpus, which is a collection of books in the public domain\n","nltk.download('gutenberg')\n","\n","# Get a plain-text version of Moby Dick (contained in a single string)\n","moby_raw = gutenberg.raw('melville-moby_dick.txt')\n","\n","# Get all the tokens in Moby Dick (as a list of strings)\n","moby_tokens = gutenberg.words('melville-moby_dick.txt')\n","\n","# Print the first 10 tokens of Moby Dick\n","print(\"First 10 tokens:\", moby_tokens[:10])\n","\n","# Print the first 250 characters of Moby Dick\n","print(\"\\nFirst 250 characters:\\n\", moby_raw[:250])"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/gutenberg.zip.\n"]},{"output_type":"stream","name":"stdout","text":["First 10 tokens: ['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.']\n","\n","First 250 characters:\n"," [Moby Dick by Herman Melville 1851]\r\n","\r\n","\r\n","ETYMOLOGY.\r\n","\r\n","(Supplied by a Late Consumptive Usher to a Grammar School)\r\n","\r\n","The pale Usher--threadbare in coat, heart, body, and brain; I see him\r\n","now.  He was ever dusting his old lexicons and grammars, with \n"]}]},{"cell_type":"markdown","metadata":{"id":"bk7r17iXgZW-"},"source":["NLTK includes a Text class for analyzing the contents of texts. Let's print a concordance for the word *Iceland*:"]},{"cell_type":"code","metadata":{"id":"YCPcW0p9gZXB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725030464487,"user_tz":240,"elapsed":710,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"24be54c0-4b9d-4044-8fe9-55af5b21ebdf"},"source":["moby_text = nltk.Text(moby_tokens)\n","moby_text.concordance('Iceland')"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Displaying 4 of 4 matches:\n","ANKS ' S AND SOLANDER ' S VOYAGE TO ICELAND IN 1772 . \" The Spermacetti Whale f\n"," an adjoining room . It was cold as Iceland -- no fire at all -- the landlord s\n"," ? Throw yourselves ! Legs ! legs ! ICELAND SAILOR . I don ' t like your floor \n","my of Sciences setting down certain Iceland Whales ( reydan - siskur , or Wrink\n"]}]},{"cell_type":"markdown","metadata":{"id":"ntDr5ACsgZXM"},"source":["NTLK offers several ways to segment text into sentences and tokenize it. Let's see how `nltk.sent_tokenize()` and `nltk.word_tokenize()` work:"]},{"cell_type":"code","metadata":{"id":"8IZ1nLySgZXQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725030465222,"user_tz":240,"elapsed":741,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"e4e4aa2c-8c6d-4317-820c-e2ba6f02c01a"},"source":["# Download the Punkt tokenizer model\n","nltk.download('punkt')\n","\n","moby_sentences = nltk.sent_tokenize(moby_raw)  # Split raw text into sentences\n","tokens = nltk.word_tokenize(moby_sentences[3])  # Split a string into tokens\n","\n","print(\"First 5 sentences:\")\n","for sentence in moby_sentences[:5]:\n","    print(\">>>\", sentence)\n","\n","print(f\"\\nTotal number of sentences: {len(moby_sentences):,}\")\n","\n","print(\"\\nTokens:\", tokens)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["First 5 sentences:\n",">>> [Moby Dick by Herman Melville 1851]\r\n","\r\n","\r\n","ETYMOLOGY.\n",">>> (Supplied by a Late Consumptive Usher to a Grammar School)\r\n","\r\n","The pale Usher--threadbare in coat, heart, body, and brain; I see him\r\n","now.\n",">>> He was ever dusting his old lexicons and grammars, with a queer\r\n","handkerchief, mockingly embellished with all the gay flags of all the\r\n","known nations of the world.\n",">>> He loved to dust his old grammars; it\r\n","somehow mildly reminded him of his mortality.\n",">>> \"While you take in hand to school others, and to teach them by what\r\n","name a whale-fish is to be called in our tongue leaving out, through\r\n","ignorance, the letter H, which almost alone maketh the signification\r\n","of the word, you deliver that which is not true.\"\n","\n","Total number of sentences: 9,852\n","\n","Tokens: ['He', 'loved', 'to', 'dust', 'his', 'old', 'grammars', ';', 'it', 'somehow', 'mildly', 'reminded', 'him', 'of', 'his', 'mortality', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"fC_OW-lUgZXo"},"source":["## Regular expressions\n","The Python standard library includes the `re` module for handling regular expressions ([reference](https://docs.python.org/3/library/re.html)). In Python, regular expression patterns should be created using *raw* strings, which are prefixed with an `r`:"]},{"cell_type":"code","metadata":{"pycharm":{"is_executing":false},"id":"I7cDMt90gZXs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725030465223,"user_tz":240,"elapsed":22,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"05d35118-cd08-4d16-f3dd-4f625467982b"},"source":["import re\n","re.findall(r'\\b\\S{9,}est\\b', moby_raw)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['sovereignest',\n"," 'off--serenest',\n"," 'monstrousest',\n"," 'Wonderfullest',\n"," 'surrenderest',\n"," 'cowardly--quickest']"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"0z_417IcgZX1"},"source":["You can capture text that matches a specific part of a pattern in a group by enclosing it within parentheses. When making substitutions with `re.sub()`, you can refer to these groups using `\\number` (e.g., `\\1` and `\\2`), where the number refers to their position in the pattern:"]},{"cell_type":"code","metadata":{"id":"aHyZVF5pgZX3","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1725030465223,"user_tz":240,"elapsed":18,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"3f1f81c2-305c-4a5e-b55f-9b9fc2c9f0d0"},"source":["another_string = \"The grapes of wrath\"\n","re.sub(r'(\\S+) of (\\S+)', r'\\2 of \\1', another_string)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The wrath of grapes'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"S-U35BXYgZYD"},"source":["NLTK offers a simple way of searching for sequences of tokens using regular expressions, where tokens can be enclosed in angle brackets:"]},{"cell_type":"code","metadata":{"pycharm":{"is_executing":false},"id":"pRChhPklgZYH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725030465774,"user_tz":240,"elapsed":563,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"e7919462-adde-415e-db6c-2f741d535f96"},"source":["# First we must create a Text object from a list of tokens\n","moby_text = nltk.Text(moby_tokens)\n","\n","# Let's search for sequences of four tokens which all begin with the letter S\n","moby_text.findall(r'<[Ss].*>{4,}')"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["ship so swiftly sped; snatch some sweet solace\n"]}]},{"cell_type":"markdown","metadata":{"id":"kIt3E060gZYQ"},"source":["You can use groups to target specific tokens."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"3L3nrg2SgZYV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725030465775,"user_tz":240,"elapsed":14,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"84d9976f-2d63-419f-9f26-2f37ce74b034"},"source":["moby_text.findall(r'<[Aa]n?>(<.+>)<ship>')"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["full; gallant; whale; modern; trading; large; Nantucket; leaking;\n","midnight; wrecked; occupied; fine; jolly; empty; great; large; leaky;\n","Nantucket; full; full; empty; whole; large; sagacious\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ksz_n_cwgZYb"},"source":["# Assignment\n","Answer the following questions and hand in your solution in Canvas before midnight, August 30th. Make a copy of this notebook (`\"File\" > \"Save a copy in Drive\"`) and enter your solutions in the cells below each question. Remember to save your file before uploading it."]},{"cell_type":"markdown","metadata":{"id":"BEcJJbIUgZYi"},"source":["### Question 1\n","Get the raw text of `carroll-alice.txt` (Alice in Wonderland) from the Gutenberg corpus in NLTK and tokenize it using `nltk.word_tokenize()`.\n","\n","1. How many tokens does it contain in total?\n","2. How many unique tokens (types) does it contain?"]},{"cell_type":"code","metadata":{"pycharm":{"is_executing":false},"id":"dsA5lgp0gZYx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725031877834,"user_tz":240,"elapsed":438,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"2a14d474-622c-49c1-9733-42845c0d286d"},"source":["# Your solution here\n","import nltk\n","from nltk.corpus import gutenberg\n","from nltk.tokenize import word_tokenize\n","# download gutenberg corpus\n","nltk.download('gutenberg')\n","# download punk_tab\n","nltk.download('punkt')\n","\n","# get plain-text version of caroll-alice.txt\n","alice_raw = gutenberg.raw('carroll-alice.txt')\n","\n","# get all tokens in alice in wonderland\n","alice_tokens = word_tokenize(alice_raw)\n","print(\"Total number of tokens:\", len(alice_tokens))\n","\n","# get unique tokens\n","print(\"Number of unique tokens:\", len(set(alice_tokens)))"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Package gutenberg is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Total number of tokens: 33494\n","Number of unique tokens: 3184\n"]}]},{"cell_type":"markdown","metadata":{"id":"5M9OMFNxgZY6"},"source":["### Question 2\n","Use `nltk.FreqDist()` to create a frequency distribution of all the tokens in Alice in Wonderland. What are the 20 most frequently occurring tokens?"]},{"cell_type":"code","metadata":{"pycharm":{"is_executing":false},"id":"tOPA_dljgZY_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725032310866,"user_tz":240,"elapsed":340,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"6ee512ff-32e8-414a-b63b-cbc53866711c"},"source":["# Your solution here\n","import nltk\n","from nltk.corpus import gutenberg\n","from nltk.tokenize import word_tokenize\n","from nltk.probability import FreqDist\n","# download gutenberg corpus\n","nltk.download('gutenberg')\n","# download punk_tab\n","nltk.download('punkt')\n","\n","# get plain-text version of caroll-alice.txt\n","alice_raw = gutenberg.raw('carroll-alice.txt')\n","\n","# get all tokens in alice in wonderland\n","alice_tokens = word_tokenize(alice_raw)\n","\n","alice_fdist = FreqDist()\n","\n","for token in alice_tokens:\n","    alice_fdist[token] += 1\n","\n","alice_fdist.pprint(20)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Package gutenberg is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["FreqDist({',': 2418, 'the': 1516, \"'\": 1309, '.': 975, 'and': 757, 'to': 717, 'a': 614, 'I': 533, 'it': 512, 'she': 506, 'of': 496, 'said': 456, '!': 450, 'Alice': 394, 'was': 361, 'in': 352, 'you': 334, 'that': 267, '--': 264, 'her': 243, ...})\n"]}]},{"cell_type":"markdown","metadata":{"id":"5ku3fBv6gZZH"},"source":["### Question 3\n","Use `nltk.sent_tokenize()` to segment Alice in Wonderland into sentences, then find the longest sentence in the book."]},{"cell_type":"code","metadata":{"pycharm":{"is_executing":false},"id":"-EuYbFqJgZZI","executionInfo":{"status":"ok","timestamp":1725030465776,"user_tz":240,"elapsed":11,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}}},"source":["# Your solution here\n","import nltk\n","from nltk.corpus import gutenberg\n","from nltk.tokenize import sent_tokenize\n","from nltk.probability import FreqDist\n","\n","# Ensure that the necessary resources are downloaded\n","nltk.download('gutenberg')\n","nltk.download('punkt')\n","\n","# Load the raw text of Alice in Wonderland\n","alice_raw = gutenberg.raw('carroll-alice.txt')\n","\n","# get sentence tokens\n","alice_sents = sent_tokenize(alice_raw)\n","\n","# sort the sentences\n","sorted_alice_sents = sorted(alice_sents, key=len, reverse=True)\n","\n","print(\"Longest sentence:\", sorted_alice_sents[0])\n","# print(\"Shortest sentence:\", sorted_alice_sents[-1])"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ExlDi0jDgZZR"},"source":["### Question 4\n","Use a regular expression to find all tokens in Alice in Wonderland that contain an *x* and end with *ed*."]},{"cell_type":"code","metadata":{"id":"TtfpRxu5gZZT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725036252368,"user_tz":240,"elapsed":728,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"83a82fb9-af28-4d80-d7a4-f026f5945012"},"source":["# Your solution here\n","import re\n","import nltk\n","from nltk.corpus import gutenberg\n","from nltk.tokenize import word_tokenize\n","\n","# get plain-text version of caroll-alice.txt\n","alice_raw = gutenberg.raw('carroll-alice.txt')\n","\n","# get all tokens in alice in wonderland\n","alice_tokens = word_tokenize(alice_raw)\n","\n","alice_text = nltk.Text(alice_tokens)\n","\n","alice_text.findall(r'<.*x.*ed>')"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["mixed; fixed; executed; expected; exclaimed; boxed; executed;\n","executed; exclaimed; exclaimed; exclaimed; explained; exclaimed;\n","executed; executed; executed; exclaimed; mixed\n"]}]},{"cell_type":"markdown","metadata":{"id":"c0rG5i_VgZZa"},"source":["### Bonus Question\n","\n","Use `re.sub()` to \"dehyphenate\" the following string:\n","\n",">It is a capital mistake to theo-  \n",">rize before one has data. Insen-  \n",">sibly one begins to twist facts  \n",">to suit theories, instead of the-  \n",">ories to suit facts.\n","\n","You will need to use groups to recombine the words. The resulting string should look like this:\n","\n",">It is a capital mistake to  \n",">theorize before one has data.  \n",">Insensibly one begins to twist facts  \n",">to suit theories, instead of  \n",">theories to suit facts.\n","\n","Remember that a \"newline\" character is represented by `\\n` in strings and regular expression patterns."]},{"cell_type":"code","metadata":{"pycharm":{"is_executing":false},"id":"zKyWgOPkgZZe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725037513246,"user_tz":240,"elapsed":222,"user":{"displayName":"ITvalcorp","userId":"10830065410979560378"}},"outputId":"46af79fd-84da-4c53-fd1f-2ac56712be87"},"source":["# Your solution here\n","hyphenated = \"\"\"\n","It is a capital mistake to theo-\n","rize before one has data. Insen-\n","sibly one begins to twist facts\n","to suit theories, instead of the-\n","ories to suit facts.\n","\"\"\"\n","\n","import re\n","\n","def dehyphenate(match):\n","    part1 = match.group(1)\n","    part2 = match.group(2)\n","\n","    return f'\\n{part1}{part2}'\n","\n","print(re.sub(r'(\\S+)-\\n(\\S+)', dehyphenate, hyphenated))\n","\n"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","It is a capital mistake to \n","theorize before one has data. \n","Insensibly one begins to twist facts\n","to suit theories, instead of \n","theories to suit facts.\n","\n"]}]}]}